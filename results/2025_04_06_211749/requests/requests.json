[
  {
    "custom_id": "82552813",
    "params": {
      "model": "claude-3-5-haiku-20241022",
      "temperature": 0,
      "max_tokens": 1024,
      "messages": [
        {
          "role": "user",
          "content": "You are an AI expert in analyzing and extracting skills from ICT job postings. Your task is to comprehensively identify all relevant hard skills and soft skills without overlooking any skills.\n\nPlease analyze the ICT job posting contained in the job posting **Job Description**\n\nKPMG technology and data team is helping banks, insurers, and nonbank clients\non their digital transformation journey to becoming datadriven organization.\nThe team is involved in a comprehensive range of consulting services and\nsolutions to our client focusing on data and technology domain as well as help\nclient solving their strategic problems focused on improving performance and\nprofitability.\n\n**Responsibilities**\n\n  * Designs, builds, and maintains data systems, databases, processing systems, and data pipelines.\n  * Work closely with the data science team to build a state-of-the-art analytical platform to facilitate analysis and A/B testing of massive search and user data\n  * Gather and process raw data at scale (including writing scripts, web scraping, calling APIs, write SQL queries, writing applications)\n  * Design and implement data structure model, data (de)normalization, data indexing, and data reporting\n  * Understand and/or able to create product metrics, ad hoc queries, and business needs documentation\n  * Perform data query performance check and tuning\n  * Solve the challenges of scaling and optimization of the internal data flow\n  * Ensure consistency and accuracy of the data, and help design and develop data models for reporting and aggregation frameworks\n  * Analyze data models, create and optimize data ingestion processes for the Data Lake through ETL technologies within a big data architecture, using Java, Python, Spark, SQL\n\n**Qualification**\n\nWe are looking for a motivated, technical minded individual with a track\nrecord of using modern technology stack to build data pipeline automation.\n\n  * Degree in Computer Engineering and Computer Science or equivalent experience\n  * Experience in design and implementation of ETL/ELT framework for complex warehouses/marts\n  * Experience (basic) as practitioner in Cloud Platform; AZURE, AWS and GCP\n  * Experience in selecting and integrating any Big Data tools and frameworks to meet required capabilities\n  * Experience in building cloud data pipelines from ingestion to consumption\n  * Experience in Python, Java, SQL\n  * Strong internal team stakeholder collaborative, diplomatic, and flexible style, able to work effectively in a matrixed organization\n  * Excellent presentation skills, including strong oral and written capabilities in English\n  * Self-motivated, results-oriented individual with the ability to progress multiple priorities concurrently\n\n and identify all relevant skills, categorized into hard skills and soft skills in a comprehensive manner.\n\nThe extracted skill names must follow standardized naming conventions to ensure consistency and usability for analysis across multiple job postings. Standardization should align with widely accepted skill taxonomies (e.g., ESCO, O*NET) and maintain uniform capitalization and phrasing.\n\nThe required output is a JSON in this format:\n{\"hard_skills\": [skill_1, skill_2, ...], \"soft_skills\": [skill_1, skill_2, ...]}\n\nMake sure that the output contains only JSON and no additional text."
        }
      ]
    }
  }
]